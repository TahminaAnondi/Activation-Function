# -*- coding: utf-8 -*-
"""Activation-Function.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1KGCCkYdknSSXmDSsnTG6bB6bgjyLXD5H
"""

import numpy as np

def sigmoid(x):
    return 1 / (1 + np.exp(-x))

def relu(x):
    return np.maximum(0, x)

def tanh(x):
    return np.tanh(x)

def leaky_relu(x, alpha=0.01):
    return np.where(x > 0, x, alpha * x)

# Test the activation functions
x = np.array([-2, -1, 0, 1, 2])

print("Input array:", x)
print("Sigmoid output:", sigmoid(x))
print("ReLU output:", relu(x))
print("Tanh output:", tanh(x))
print("Leaky ReLU output:", leaky_relu(x))